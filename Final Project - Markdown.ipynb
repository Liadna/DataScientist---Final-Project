{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist - Political Speeches (Final Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final project deals with taking a corpus of political speeches of three politicians and learns it. After that, it generates new speeches for everyone of them. The last part is classifying which speech is related to whom.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Collecting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we looked for american politicians with at least 50 speeches (published with transcript).\n",
    "We found two site that reserved the speeches for american presidents:\n",
    "1. http://www.americanrhetoric.com\n",
    "2. http://www.presidency.ucsb.edu\n",
    "\n",
    "The first site was provided us speeches for Barack Obama and G.W.Bush and the second site for Bill Clinton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Corpus: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus cosists 466 Speeches of Barack Obama, 87 Speeches of G.W.Bush ans 87 Speeches of Bill Clinton.\n",
    "You can find the corpus in this link: https://github.com/Liadna/DataScientist---Final-Project/tree/master/PoliticalSpeeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Crawler: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe Crawler works in different ways for each site:\n",
    "1. For the first site (\"http://www.americanrhetoric.com\"), it parses the president page and get all the PDF URLs. For every URL, it the the PDF text and writes it into a txt file.\n",
    "2. For the second site (\"http://www.presidency.ucsb.edu\"), we saved a list with the relevant id speeches. For every speech, the it saves the relevant text into a txt file.\n",
    "\n",
    "You can find the Crawler code in this link: https://github.com/Liadna/DataScientist---Final-Project/blob/master/PoliticalSpeechesCrawler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curpos to CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Project, We were asked for creating the corpus as Dataset - we created a CSV file.\n",
    "The CSV file consists two columns: the first one is the speech and the second is the president name.\n",
    "    \n",
    "The new size of the Dataset is: 87 Speeches of Barack Obama, 87 Speeches of G.W.Bush ans 87 Speeches of Bill Clinton - 261 Records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the code in this link: https://github.com/Liadna/DataScientist---Final-Project/blob/master/corpus_to_csv.py.\n",
    "\n",
    "And also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import string\n",
    "\n",
    "chars = string.printable\n",
    "punc = string.punctuation\n",
    "letters = string.letters\n",
    "digits = string.digits\n",
    "\n",
    "speeches = {\"obama\": [], \"bush\": [], \"clinton\": []}\n",
    "\n",
    "# Function receives a path to the folder containing 3 folders, one for each president\n",
    "def create_csv(path):\n",
    "    # Presidents folders\n",
    "    presidents = {\"obama\" : \"Obama_Speeches\", \"bush\" : \"Bush_Speeches\", \"clinton\" : \"Clinton_Speeches\"}\n",
    "    for key, value in presidents.iteritems():\n",
    "        l = []\n",
    "        # Create list of the speeches for each president\n",
    "        for file_name in os.listdir(path + \"\\\\\" + value):\n",
    "            with open(path + \"\\\\\" + value + \"\\\\\" + file_name) as f:\n",
    "                # Remove extra spaces, tabs, newlines\n",
    "                speech = \" \".join(f.read().strip().split(\" \"))\n",
    "                speech_clean = \"\"\n",
    "\n",
    "                # Clear unwanted symbols, leave only letters/numbers and punctuation\n",
    "                for c in speech:\n",
    "                    if c in digits or c in letters or c in punc or c == ' ':\n",
    "                        speech_clean += c\n",
    "                l.append(speech_clean)\n",
    "        speeches[key] = l\n",
    "\n",
    "    # write data to csv file\n",
    "    with open(path + \"\\data1.csv\", \"wb\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=\",\")\n",
    "\n",
    "        for key, value in speeches.iteritems():\n",
    "            for row in value:\n",
    "                writer.writerow([row, key])\n",
    "\n",
    "path = \"D:\\Programs\\PythonWorkspace\\DataScienceProject\\PoliticalSpeeches\"\n",
    "create_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CSV file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the CSV file in this link: https://github.com/Liadna/DataScientist---Final-Project/blob/master/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Data Cleaning and Classifing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
